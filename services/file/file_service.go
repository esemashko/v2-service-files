package file

import (
	"archive/zip"
	"bytes"
	"context"
	"fmt"
	"io"
	"main/ctxkeys"
	"main/ent"
	"main/ent/file"
	"main/ent/user"
	fileprivacy "main/privacy/file"
	"main/s3"
	"main/types"
	"main/utils"
	"mime"
	"path/filepath"
	"strings"
	"time"

	"github.com/99designs/gqlgen/graphql"
	"github.com/google/uuid"
	"go.uber.org/zap"
)

const (
	// DefaultPresignedURLExpiration –≤—Ä–µ–º—è –∂–∏–∑–Ω–∏ pre-signed URL –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (1 —á–∞—Å)
	DefaultPresignedURLExpiration = time.Hour
	// MaxPresignedURLExpiration –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –∂–∏–∑–Ω–∏ pre-signed URL (24 —á–∞—Å–∞)
	MaxPresignedURLExpiration = 24 * time.Hour
	// MaxBatchArchiveFiles –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –≤ –∞—Ä—Ö–∏–≤–µ
	MaxBatchArchiveFiles = 50
)

// FileService provides file management operations
type FileService struct {
	s3Service    *s3.S3Service
	auditService *FileAuditService
}

// hasAdminRole –ø—Ä–æ–≤–µ—Ä—è–µ—Ç, –∏–º–µ–µ—Ç –ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∞–¥–º–∏–Ω—Å–∫—É—é —Ä–æ–ª—å
func (s *FileService) hasAdminRole(ctx context.Context) bool {
	localUser := ctxkeys.GetLocalUser(ctx)
	if localUser == nil {
		return false
	}

	userRole, err := localUser.Role(ctx)
	if err != nil {
		return false
	}

	return userRole != nil && types.IsRoleHigherOrEqual(userRole.Code, types.RoleAdmin)
}

// isMember –ø—Ä–æ–≤–µ—Ä—è–µ—Ç, –∏–º–µ–µ—Ç –ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ä–æ–ª—å member –∏–ª–∏ –≤—ã—à–µ
func (s *FileService) isMember(ctx context.Context) bool {
	localUser := ctxkeys.GetLocalUser(ctx)
	if localUser == nil {
		return false
	}

	userRole, err := localUser.Role(ctx)
	if err != nil {
		return false
	}

	return userRole != nil && types.IsRoleHigherOrEqual(userRole.Code, types.RoleMember)
}

// canDownloadFile –ø—Ä–æ–≤–µ—Ä—è–µ—Ç, –º–æ–∂–µ—Ç –ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–∫–∞—á–∏–≤–∞—Ç—å —Ñ–∞–π–ª
func (s *FileService) canDownloadFile(ctx context.Context, client *ent.Client, fileID uuid.UUID) error {
	// –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ —Ñ–∞–π–ª —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
	if _, err := client.File.Query().
		Where(file.ID(fileID)).
		Only(ctx); err != nil {
		if ent.IsNotFound(err) {
			return fmt.Errorf("%s", utils.T(ctx, "error.file.not_found"))
		}
		return fmt.Errorf("%s", utils.T(ctx, "error.file.get_failed"))
	}

	// –ê—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ —Ä–æ–ª—å
	userID := ctxkeys.GetUserID(ctx)
	var userRoleCode string
	if localUser := ctxkeys.GetLocalUser(ctx); localUser != nil {
		if userRole, err := localUser.Role(ctx); err == nil && userRole != nil {
			userRoleCode = userRole.Code
		}
	}

	// –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø —á–µ—Ä–µ–∑ —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–µ–¥–∏–∫–∞—Ç—ã (–∞–≤—Ç–æ—Ä —Ñ–∞–π–ª–∞, –¥–æ—Å—Ç—É–ø –∫ —Ç–∏–∫–µ—Ç—É/–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—é/—á–∞—Ç—É)
	if err := fileprivacy.CanAccessFile(ctx, client, userID, userRoleCode, fileID); err != nil {
		return fmt.Errorf("%s", utils.T(ctx, "error.file.view_permission_denied"))
	}
	return nil
}

// CanUpdateFile –ø—Ä–æ–≤–µ—Ä—è–µ—Ç, –º–æ–∂–µ—Ç –ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å —Ñ–∞–π–ª
func (s *FileService) CanUpdateFile(ctx context.Context, client *ent.Client, fileID uuid.UUID) error {
	userID := ctxkeys.GetUserID(ctx)

	// –ü–æ–ª—É—á–∞–µ–º —Ñ–∞–π–ª —Å –∑–∞–≥—Ä—É–∑—á–∏–∫–æ–º
	fileRecord, err := client.File.Query().
		Where(file.ID(fileID)).
		WithUploader().
		Only(ctx)
	if err != nil {
		if ent.IsNotFound(err) {
			return fmt.Errorf("%s", utils.T(ctx, "error.file.not_found"))
		}
		return fmt.Errorf("%s", utils.T(ctx, "error.file.get_failed"))
	}

	// –í–ª–∞–¥–µ–ª—å—Ü—ã –∏ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—ã –º–æ–≥—É—Ç —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –ª—é–±—ã–µ —Ñ–∞–π–ª—ã
	if s.hasAdminRole(ctx) {
		return nil
	}

	// –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –º–æ–≥—É—Ç —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ —Å–≤–æ–∏ —Ñ–∞–π–ª—ã
	if fileRecord.Edges.Uploader != nil && fileRecord.Edges.Uploader.ID == userID {
		return nil
	}

	return fmt.Errorf("%s", utils.T(ctx, "error.file.update_permission_denied"))
}

// CanUploadFile –ø—Ä–æ–≤–µ—Ä—è–µ—Ç, –º–æ–∂–µ—Ç –ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∑–∞–≥—Ä—É–∂–∞—Ç—å —Ñ–∞–π–ª—ã
func (s *FileService) CanUploadFile(ctx context.Context) error {
	userID := ctxkeys.GetUserID(ctx)
	if userID != uuid.Nil {
		return nil
	}
	return fmt.Errorf("%s", utils.T(ctx, "error.file.upload_permission_denied"))
}

// CanDeleteFile –ø—Ä–æ–≤–µ—Ä—è–µ—Ç, –º–æ–∂–µ—Ç –ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —É–¥–∞–ª—è—Ç—å —Ñ–∞–π–ª
func (s *FileService) CanDeleteFile(ctx context.Context, client *ent.Client, fileID uuid.UUID) error {
	userID := ctxkeys.GetUserID(ctx)

	// –ü–æ–ª—É—á–∞–µ–º —Ñ–∞–π–ª —Å –∑–∞–≥—Ä—É–∑—á–∏–∫–æ–º
	fileRecord, err := client.File.Query().
		Where(file.ID(fileID)).
		WithUploader().
		Only(ctx)
	if err != nil {
		if ent.IsNotFound(err) {
			return fmt.Errorf("%s", utils.T(ctx, "error.file.not_found"))
		}
		return fmt.Errorf("%s", utils.T(ctx, "error.file.get_failed"))
	}

	// –í–ª–∞–¥–µ–ª—å—Ü—ã –∏ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—ã –º–æ–≥—É—Ç —É–¥–∞–ª—è—Ç—å –ª—é–±—ã–µ —Ñ–∞–π–ª—ã
	if s.hasAdminRole(ctx) {
		return nil
	}

	// –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –º–æ–≥—É—Ç —É–¥–∞–ª—è—Ç—å —Ç–æ–ª—å–∫–æ —Å–≤–æ–∏ —Ñ–∞–π–ª—ã
	if fileRecord.Edges.Uploader != nil && fileRecord.Edges.Uploader.ID == userID {
		return nil
	}

	return fmt.Errorf("%s", utils.T(ctx, "error.file.delete_permission_denied"))
}

// CanViewFile –ø—Ä–æ–≤–µ—Ä—è–µ—Ç, –º–æ–∂–µ—Ç –ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å–º–∞—Ç—Ä–∏–≤–∞—Ç—å —Ñ–∞–π–ª
func (s *FileService) CanViewFile(ctx context.Context, client *ent.Client, fileID uuid.UUID) error {
	// –õ–æ–≥–∏–∫–∞ —Ç–∞–∫–∞—è –∂–µ, –∫–∞–∫ –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞
	return s.canDownloadFile(ctx, client, fileID)
}

// removed: GetFilePermissions ‚Äî deprecated in favor of field-level canDelete

// NewFileService creates a new file service
func NewFileService() *FileService {
	return &FileService{
		s3Service:    s3.NewS3Service(),
		auditService: NewFileAuditService(),
	}
}

// UploadFileInput contains file upload parameters
type UploadFileInput struct {
	Upload      *graphql.Upload
	Description *string
}

// FileDownloadUrlResult —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–∞–Ω–Ω—ã–µ –æ pre-signed URL –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞
type FileDownloadUrlResult struct {
	URL       string
	ExpiresAt time.Time
}

// BatchDownloadUrlResult —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–∞–Ω–Ω—ã–µ –æ pre-signed URL –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –∞—Ä—Ö–∏–≤–∞
type BatchDownloadUrlResult struct {
	URL         string
	ExpiresAt   time.Time
	ArchiveName string
	TotalFiles  int
}

// GetFileDownloadURL –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç pre-signed URL –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –æ–¥–∏–Ω–æ—á–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
func (s *FileService) GetFileDownloadURL(ctx context.Context, client *ent.Client, fileID uuid.UUID) (*FileDownloadUrlResult, error) {
	// üîí [POLICY CHECK] –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∞–≤–∞ –Ω–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
	if err := s.canDownloadFile(ctx, client, fileID); err != nil {
		return nil, err
	}

	// –ü–æ–ª—É—á–∞–µ–º —Ñ–∞–π–ª –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
	fileRecord, err := client.File.Query().
		Where(file.ID(fileID)).
		WithUploader().
		Only(ctx)
	if err != nil {
		if ent.IsNotFound(err) {
			return nil, fmt.Errorf("%s", utils.T(ctx, "error.file.not_found"))
		}
		return nil, fmt.Errorf("%s", utils.T(ctx, "error.file.get_failed"))
	}

	// –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º pre-signed URL —Å –≤—Ä–µ–º–µ–Ω–µ–º –∂–∏–∑–Ω–∏ 1 —á–∞—Å
	url, err := s.s3Service.GetPresignedURL(ctx, fileRecord.StorageKey, DefaultPresignedURLExpiration)
	if err != nil {
		if strings.Contains(err.Error(), "S3 credentials are not configured") {
			return nil, fmt.Errorf("%s", utils.T(ctx, "error.file.s3_not_configured"))
		}
		return nil, fmt.Errorf("%s", utils.T(ctx, "error.file.url_generation_failed"))
	}

	// üìä [AUDIT] –õ–æ–≥–∏—Ä—É–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é URL –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
	s.auditService.LogFileDownloadUrlGeneration(ctx, client, fileID)

	return &FileDownloadUrlResult{
		URL:       url,
		ExpiresAt: time.Now().Add(DefaultPresignedURLExpiration),
	}, nil
}

// GetBatchDownloadURL —Å–æ–∑–¥–∞–µ—Ç ZIP –∞—Ä—Ö–∏–≤ –∏–∑ —É–∫–∞–∑–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç pre-signed URL –¥–ª—è –µ–≥–æ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
func (s *FileService) GetBatchDownloadURL(ctx context.Context, client *ent.Client, fileIDs []uuid.UUID, archiveName string) (*BatchDownloadUrlResult, error) {
	// –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
	if len(fileIDs) == 0 {
		return nil, fmt.Errorf("%s", utils.T(ctx, "error.file.no_files_selected"))
	}
	if len(fileIDs) > MaxBatchArchiveFiles {
		return nil, fmt.Errorf("%s", utils.T(ctx, "error.file.too_many_files_selected"))
	}

	// –ü–æ–ª—É—á–∞–µ–º –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∞–≤–∞ –Ω–∞ –≤—Å–µ —Ñ–∞–π–ª—ã
	files, err := s.validateAndGetFilesForBatch(ctx, client, fileIDs)
	if err != nil {
		return nil, err
	}

	if len(files) == 0 {
		return nil, fmt.Errorf("%s", utils.T(ctx, "error.file.no_accessible_files"))
	}

	// –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–º—è –∞—Ä—Ö–∏–≤–∞, –µ—Å–ª–∏ –Ω–µ –∑–∞–¥–∞–Ω–æ
	if archiveName == "" {
		archiveName = fmt.Sprintf("files_%s.zip", time.Now().Format("20060102_150405"))
	}
	if !strings.HasSuffix(archiveName, ".zip") {
		archiveName += ".zip"
	}

	// –°–æ–∑–¥–∞–µ–º ZIP –∞—Ä—Ö–∏–≤ –≤ –ø–∞–º—è—Ç–∏
	var buffer bytes.Buffer
	zipWriter := zip.NewWriter(&buffer)

	usedFilenames := make(map[string]bool)

	for _, fileRecord := range files {
		if err := s.addFileToZipFromS3(ctx, zipWriter, fileRecord, usedFilenames); err != nil {
			utils.Logger.Error("Failed to add file to ZIP archive",
				zap.Error(err),
				zap.String("file_id", fileRecord.ID.String()),
				zap.String("filename", fileRecord.OriginalName))
			// –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –¥—Ä—É–≥–∏—Ö —Ñ–∞–π–ª–æ–≤
			continue
		}

		// üìä [AUDIT] –õ–æ–≥–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π —Ñ–∞–π–ª –æ—Ç–¥–µ–ª—å–Ω–æ –∫–∞–∫ —Å–∫–∞—á–∞–Ω–Ω—ã–π –≤ —Å–æ—Å—Ç–∞–≤–µ –∞—Ä—Ö–∏–≤–∞
		s.auditService.LogFileBatchDownload(ctx, client, fileRecord.ID, archiveName, len(files))
	}

	if err := zipWriter.Close(); err != nil {
		return nil, fmt.Errorf("%s", utils.T(ctx, "error.file.archive_creation_failed"))
	}

	// –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—Ä—Ö–∏–≤ –≤ S3 —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º –∫–ª—é—á–æ–º
	archiveStorageKey := s.generateTemporaryArchiveKey(archiveName)
	err = s.s3Service.UploadTemporaryFile(ctx, &buffer, archiveStorageKey, "application/zip")
	if err != nil {
		return nil, fmt.Errorf("%s", utils.T(ctx, "error.file.archive_upload_failed"))
	}

	// –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º pre-signed URL –¥–ª—è –∞—Ä—Ö–∏–≤–∞
	url, err := s.s3Service.GetPresignedURL(ctx, archiveStorageKey, DefaultPresignedURLExpiration)
	if err != nil {
		// –£–¥–∞–ª—è–µ–º –∞—Ä—Ö–∏–≤ –ø—Ä–∏ –æ—à–∏–±–∫–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ URL
		_ = s.s3Service.DeleteFile(ctx, archiveStorageKey)
		return nil, fmt.Errorf("%s", utils.T(ctx, "error.file.url_generation_failed"))
	}

	// –ü–ª–∞–Ω–∏—Ä—É–µ–º —É–¥–∞–ª–µ–Ω–∏–µ –∞—Ä—Ö–∏–≤–∞ —á–µ—Ä–µ–∑ 1 —á–∞—Å
	go s.scheduleArchiveDeletion(ctx, archiveStorageKey, DefaultPresignedURLExpiration)

	utils.Logger.Info("Batch download archive created",
		zap.Int("total_files", len(files)),
		zap.Int("requested_files", len(fileIDs)),
		zap.String("archive_name", archiveName),
		zap.String("storage_key", archiveStorageKey))

	return &BatchDownloadUrlResult{
		URL:         url,
		ExpiresAt:   time.Now().Add(DefaultPresignedURLExpiration),
		ArchiveName: archiveName,
		TotalFiles:  len(files),
	}, nil
}

// validateAndGetFilesForBatch –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –ø—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞ –∏ –ø–æ–ª—É—á–∞–µ—Ç —Ñ–∞–π–ª—ã –¥–ª—è –≥—Ä—É–ø–ø–æ–≤–æ–≥–æ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
func (s *FileService) validateAndGetFilesForBatch(ctx context.Context, client *ent.Client, fileIDs []uuid.UUID) ([]*ent.File, error) {
	// –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
	files, err := client.File.Query().
		Where(file.IDIn(fileIDs...)).
		WithUploader().
		All(ctx)
	if err != nil {
		return nil, fmt.Errorf("%s", utils.T(ctx, "error.file.get_files_failed"))
	}

	// –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∞–≤–∞ –Ω–∞ –∫–∞–∂–¥—ã–π —Ñ–∞–π–ª
	var accessibleFiles []*ent.File
	for _, fileRecord := range files {
		if err := s.canDownloadFile(ctx, client, fileRecord.ID); err != nil {
			utils.Logger.Warn("File access denied in batch download",
				zap.String("file_id", fileRecord.ID.String()),
				zap.Error(err))
			// –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∞–π–ª—ã –±–µ–∑ –¥–æ—Å—Ç—É–ø–∞, –Ω–æ –Ω–µ —Ñ–µ–π–ª–∏–º –≤–µ—Å—å –∑–∞–ø—Ä–æ—Å
			continue
		}
		accessibleFiles = append(accessibleFiles, fileRecord)
	}

	return accessibleFiles, nil
}

// addFileToZipFromS3 –¥–æ–±–∞–≤–ª—è–µ—Ç —Ñ–∞–π–ª –∏–∑ S3 –≤ ZIP-–∞—Ä—Ö–∏–≤
func (s *FileService) addFileToZipFromS3(ctx context.Context, zipWriter *zip.Writer, fileRecord *ent.File, usedFilenames map[string]bool) error {
	// –ü–æ–ª—É—á–∞–µ–º —Ñ–∞–π–ª –∏–∑ S3
	s3Object, err := s.s3Service.GetFileObject(ctx, fileRecord.StorageKey)
	if err != nil {
		return fmt.Errorf("failed to get file from S3: %w", err)
	}
	defer s3Object.Close()

	// –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞ –≤ –∞—Ä—Ö–∏–≤–µ
	filename := s.generateUniqueFilename(fileRecord.OriginalName, usedFilenames)

	// –°–æ–∑–¥–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Ñ–∞–π–ª–∞ –≤ ZIP
	header := &zip.FileHeader{
		Name:   filename,
		Method: zip.Store, // –ë–µ–∑ —Å–∂–∞—Ç–∏—è –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
	}
	header.SetModTime(fileRecord.CreateTime)

	// –°–æ–∑–¥–∞–µ–º writer –¥–ª—è —Ñ–∞–π–ª–∞ –≤ –∞—Ä—Ö–∏–≤–µ
	fileWriter, err := zipWriter.CreateHeader(header)
	if err != nil {
		return fmt.Errorf("failed to create file header in ZIP: %w", err)
	}

	// –ö–æ–ø–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞ –≤ –∞—Ä—Ö–∏–≤
	written, err := io.Copy(fileWriter, s3Object)
	if err != nil {
		return fmt.Errorf("failed to write file to ZIP: %w", err)
	}

	utils.Logger.Debug("File added to ZIP archive",
		zap.String("file_id", fileRecord.ID.String()),
		zap.String("filename", filename),
		zap.Int64("size", written))

	return nil
}

// generateUniqueFilename —Å–æ–∑–¥–∞–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞ –¥–ª—è –∞—Ä—Ö–∏–≤–∞
func (s *FileService) generateUniqueFilename(originalName string, usedFilenames map[string]bool) string {
	if !usedFilenames[originalName] {
		usedFilenames[originalName] = true
		return originalName
	}

	ext := filepath.Ext(originalName)
	nameWithoutExt := strings.TrimSuffix(originalName, ext)

	counter := 1
	for {
		newName := fmt.Sprintf("%s (%d)%s", nameWithoutExt, counter, ext)
		if !usedFilenames[newName] {
			usedFilenames[newName] = true
			return newName
		}
		counter++
	}
}

// generateTemporaryArchiveKey –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–ª—é—á –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –∞—Ä—Ö–∏–≤–∞ –≤ –∫–æ—Ä–Ω–µ–≤–æ–π –≤—Ä–µ–º–µ–Ω–Ω–æ–π –ø–∞–ø–∫–µ S3
func (s *FileService) generateTemporaryArchiveKey(archiveName string) string {
	timestamp := time.Now().Format("2006/01/02/15")
	id := uuid.New().String()[:8]

	// –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É –≤ –∫–æ—Ä–Ω–µ –±–∞–∫–µ—Ç–∞
	return fmt.Sprintf("temp/%s/%s-%s", timestamp, strings.TrimSuffix(archiveName, ".zip"), id) + ".zip"
}

// scheduleArchiveDeletion –ø–ª–∞–Ω–∏—Ä—É–µ—Ç —É–¥–∞–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –∞—Ä—Ö–∏–≤–∞ —á–µ—Ä–µ–∑ —É–∫–∞–∑–∞–Ω–Ω–æ–µ –≤—Ä–µ–º—è
func (s *FileService) scheduleArchiveDeletion(ctx context.Context, storageKey string, delay time.Duration) {
	// –ñ–¥–µ–º —É–∫–∞–∑–∞–Ω–Ω–æ–µ –≤—Ä–µ–º—è
	time.Sleep(delay)

	// –£–¥–∞–ª—è–µ–º –∞—Ä—Ö–∏–≤ –∏–∑ S3
	if err := s.s3Service.DeleteFile(ctx, storageKey); err != nil {
		utils.Logger.Error("Failed to delete temporary archive",
			zap.Error(err),
			zap.String("storage_key", storageKey))
	} else {
		utils.Logger.Info("Temporary archive deleted successfully",
			zap.String("storage_key", storageKey))
	}
}

// UploadFile uploads a file to S3 and creates a file record in database
func (s *FileService) UploadFile(ctx context.Context, client *ent.Client, input UploadFileInput) (*ent.File, error) {
	utils.Logger.Info("UploadFile method called",
		zap.String("filename", input.Upload.Filename),
		zap.Int64("file_size", input.Upload.Size),
		zap.Bool("client_not_nil", client != nil))

	if input.Upload == nil {
		return nil, fmt.Errorf("%s", utils.T(ctx, "error.file.no_file"))
	}

	upload := input.Upload

	// Validate filename length (prevent S3 key length issues)
	if len(upload.Filename) > 200 {
		return nil, fmt.Errorf("%s", utils.T(ctx, "error.file.filename_too_long"))
	}

	// Validate file size (limit to 100MB)
	const maxFileSize = 100 * 1024 * 1024 // 100MB
	if upload.Size > maxFileSize {
		return nil, fmt.Errorf("%s", utils.T(ctx, "error.file.size_too_large"))
	}

	// Detect content type if not provided or empty
	contentType := upload.ContentType
	if contentType == "" {
		contentType = mime.TypeByExtension(filepath.Ext(upload.Filename))
		if contentType == "" {
			contentType = "application/octet-stream"
		}
	}

	// üìä [STORAGE LIMIT CHECK] –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –ø–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π
	if err := s.s3Service.CheckStorageLimitWithFilename(ctx, upload.Filename, upload.Size); err != nil {
		utils.Logger.Info("Storage limit check failed",
			zap.String("filename", upload.Filename),
			zap.Int64("file_size", upload.Size),
			zap.Error(err))

		// –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ –æ—à–∏–±–∫–æ–π –Ω–µ–∑–∞—Å—Ç—Ä–æ–µ–Ω–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
		if storageNotConfiguredErr, ok := err.(*s3.StorageNotConfiguredError); ok {
			utils.Logger.Info("Logging storage not configured violation",
				zap.String("filename", storageNotConfiguredErr.FileName),
				zap.Int64("file_size", storageNotConfiguredErr.FileSize))

			// –õ–æ–≥–∏—Ä—É–µ–º –ø–æ–ø—ã—Ç–∫—É –∑–∞–≥—Ä—É–∑–∫–∏ –≤ –Ω–µ–∑–∞—Å—Ç—Ä–æ–µ–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
			utils.Logger.Info("About to call LogStorageNotConfiguredViolation",
				zap.String("filename", storageNotConfiguredErr.FileName),
				zap.Int64("file_size", storageNotConfiguredErr.FileSize))

			s.auditService.LogStorageNotConfiguredViolation(ctx, client,
				storageNotConfiguredErr.FileName,
				storageNotConfiguredErr.FileSize)

			utils.Logger.Info("LogStorageNotConfiguredViolation call completed")

			// –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ª–æ–∫–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—É—é –æ—à–∏–±–∫—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
			return nil, fmt.Errorf("%s", utils.T(ctx, "error.file.storage_not_configured"))
		}

		// –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ –æ—à–∏–±–∫–æ–π –ø—Ä–µ–≤—ã—à–µ–Ω–∏—è –ª–∏–º–∏—Ç–∞ —Å –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è –∞—É–¥–∏—Ç–∞
		if storageLimitErr, ok := err.(*s3.StorageLimitError); ok {
			utils.Logger.Info("Logging storage limit violation",
				zap.String("filename", storageLimitErr.FileName),
				zap.Int64("file_size", storageLimitErr.FileSize),
				zap.Int64("current_usage", storageLimitErr.CurrentUsage),
				zap.Int64("storage_limit", storageLimitErr.StorageLimit))

			// –õ–æ–≥–∏—Ä—É–µ–º –ø–æ–ø—ã—Ç–∫—É –ø—Ä–µ–≤—ã—à–µ–Ω–∏—è –ª–∏–º–∏—Ç–∞
			utils.Logger.Info("About to call LogStorageLimitViolation",
				zap.String("filename", storageLimitErr.FileName),
				zap.Int64("file_size", storageLimitErr.FileSize))

			s.auditService.LogStorageLimitViolation(ctx, client,
				storageLimitErr.FileName,
				storageLimitErr.FileSize,
				storageLimitErr.CurrentUsage,
				storageLimitErr.StorageLimit)

			utils.Logger.Info("LogStorageLimitViolation call completed")

			// –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ª–æ–∫–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—É—é –æ—à–∏–±–∫—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
			return nil, fmt.Errorf("%s", utils.T(ctx, "error.file.storage_limit_exceeded", map[string]interface{}{
				"current_usage": storageLimitErr.CurrentUsage64,
				"current_unit":  storageLimitErr.CurrentUnit,
				"limit":         storageLimitErr.Limit64,
				"limit_unit":    storageLimitErr.LimitUnit,
			}))
		}

		// –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ –æ—à–∏–±–∫–æ–π —Ñ–∞–π–ª–∞, –∫–æ—Ç–æ—Ä—ã–π —Å–∞–º –ø–æ —Å–µ–±–µ –±–æ–ª—å—à–µ –ª–∏–º–∏—Ç–∞
		if fileTooLargeErr, ok := err.(*s3.FileTooLargeError); ok {
			utils.Logger.Info("File too large for storage limit",
				zap.String("filename", fileTooLargeErr.FileName),
				zap.Int64("file_size", fileTooLargeErr.FileSize))

			// –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ª–æ–∫–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—É—é –æ—à–∏–±–∫—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
			return nil, fmt.Errorf("%s", utils.T(ctx, "error.file.file_too_large_for_storage", map[string]interface{}{
				"file_size":  fileTooLargeErr.FileSize64,
				"file_unit":  fileTooLargeErr.FileUnit,
				"limit":      fileTooLargeErr.Limit64,
				"limit_unit": fileTooLargeErr.LimitUnit,
			}))
		}
		return nil, err
	}

	// Upload to S3
	storageKey, err := s.s3Service.UploadFile(ctx, upload.File, upload.Filename, contentType)
	if err != nil {
		// üîç [DEBUG] –õ–æ–≥–∏—Ä—É–µ–º –¥–µ—Ç–∞–ª—å–Ω—É—é –æ—à–∏–±–∫—É S3 –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
		utils.Logger.Error("S3 upload failed - detailed error",
			zap.Error(err),
			zap.String("filename", upload.Filename),
			zap.String("content_type", contentType),
			zap.Int64("file_size", upload.Size))

		// Check if it's S3 configuration error
		if strings.Contains(err.Error(), "S3 credentials are not configured") {
			return nil, fmt.Errorf("%s", utils.T(ctx, "error.file.s3_not_configured"))
		}

		// Check for timeout errors
		if strings.Contains(err.Error(), "timeout") || strings.Contains(err.Error(), "deadline exceeded") {
			utils.Logger.Error("S3 upload timeout detected",
				zap.Error(err),
				zap.String("filename", upload.Filename))
			return nil, fmt.Errorf("%s", utils.T(ctx, "error.file.upload_timeout"))
		}

		// Check for connection errors
		if strings.Contains(err.Error(), "connection") || strings.Contains(err.Error(), "network") {
			utils.Logger.Error("S3 connection error detected",
				zap.Error(err),
				zap.String("filename", upload.Filename))
			return nil, fmt.Errorf("%s", utils.T(ctx, "error.file.s3_connection_failed"))
		}

		return nil, fmt.Errorf("%s", utils.T(ctx, "error.file.upload_failed"))
	}

	// Get user from context for database record
	localUser := ctxkeys.GetLocalUser(ctx)
	if localUser == nil {
		// Cleanup S3 file if user not found
		if deleteErr := s.s3Service.DeleteFile(ctx, storageKey); deleteErr != nil {
			utils.Logger.Error("Failed to cleanup S3 file after user context error",
				zap.Error(deleteErr),
				zap.String("storage_key", storageKey),
			)
		}
		return nil, fmt.Errorf("%s", utils.T(ctx, "error.user.not_authenticated"))
	}

	// Create file record in database
	ctxWithClient := ent.NewContext(ctx, client)
	fileRecord, err := client.File.Create().
		SetOriginalName(upload.Filename).
		SetStorageKey(storageKey).
		SetMimeType(contentType).
		SetSize(upload.Size).
		SetUploaderID(localUser.ID).
		SetNillableDescription(input.Description).
		Save(ctxWithClient)
	if err != nil {
		// If database save fails, try to cleanup S3 file
		if deleteErr := s.s3Service.DeleteFile(ctx, storageKey); deleteErr != nil {
			utils.Logger.Error("Failed to cleanup S3 file after database error",
				zap.Error(deleteErr),
				zap.String("storage_key", storageKey),
			)
		}
		return nil, fmt.Errorf("%s", utils.T(ctx, "error.file.create_failed"))
	}

	return fileRecord, nil
}

// DeleteFile deletes a file from both database and S3
func (s *FileService) DeleteFile(ctx context.Context, client *ent.Client, fileID uuid.UUID) error {
	ctxWithClient := ent.NewContext(ctx, client)

	// –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ –ø–µ—Ä–µ–¥ —É–¥–∞–ª–µ–Ω–∏–µ–º
	_, err := client.File.Query().
		Where(file.ID(fileID)).
		Only(ctxWithClient)
	if err != nil {
		if ent.IsNotFound(err) {
			return fmt.Errorf("%s", utils.T(ctx, "error.file.not_found"))
		}
		return fmt.Errorf("%s", utils.T(ctx, "error.file.get_failed"))
	}

	// –ñ–µ—Å—Ç–∫–æ —É–¥–∞–ª—è–µ–º —Ñ–∞–π–ª –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
	err = client.File.DeleteOneID(fileID).
		Exec(ctxWithClient)
	if err != nil {
		return fmt.Errorf("%s", utils.T(ctx, "error.file.delete_failed"))
	}

	// Delete from S3 –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —á–µ—Ä–µ–∑ —Ö—É–∫ WithFileS3Deletion()

	return nil
}

// GetFilesByUser returns files uploaded by a specific user
func (s *FileService) GetFilesByUser(ctx context.Context, client *ent.Client, userID uuid.UUID, limit, offset int) ([]*ent.File, error) {
	ctxWithClient := ent.NewContext(ctx, client)

	files, err := client.File.Query().
		Where(file.HasUploaderWith(user.ID(userID))).
		Limit(limit).
		Offset(offset).
		Order(ent.Desc(file.FieldCreateTime)).
		All(ctxWithClient)
	if err != nil {
		return nil, fmt.Errorf("%s", utils.T(ctx, "error.file.get_files_failed"))
	}

	return files, nil
}

// GetFileInfo returns file information
func (s *FileService) GetFileInfo(ctx context.Context, client *ent.Client, fileID uuid.UUID) (*ent.File, error) {
	ctxWithClient := ent.NewContext(ctx, client)

	fileRecord, err := client.File.Query().
		Where(file.ID(fileID)).
		WithUploader().
		Only(ctxWithClient)
	if err != nil {
		if ent.IsNotFound(err) {
			return nil, fmt.Errorf("%s", utils.T(ctx, "error.file.not_found"))
		}
		return nil, fmt.Errorf("%s", utils.T(ctx, "error.file.get_failed"))
	}

	return fileRecord, nil
}

// UpdateFilesBatch: visibility removed, method retained to avoid breaking callers until resolvers are cleaned
func (s *FileService) UpdateFilesBatch(ctx context.Context, client *ent.Client, fileIDs []uuid.UUID) ([]*ent.File, int, error) {
	// –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
	if len(fileIDs) == 0 {
		return nil, 0, fmt.Errorf("%s", utils.T(ctx, "error.file.no_files_selected"))
	}

	// –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∑–∞ —Ä–∞–∑
	const maxBatchUpdateFiles = 100
	if len(fileIDs) > maxBatchUpdateFiles {
		return nil, 0, fmt.Errorf("%s", utils.T(ctx, "error.file.too_many_files_for_batch_update"))
	}

	// –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∞–≤–∞ –Ω–∞ –≤—Å–µ —Ñ–∞–π–ª—ã –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
	for _, fileID := range fileIDs {
		if err := s.CanUpdateFile(ctx, client, fileID); err != nil {
			return nil, 0, fmt.Errorf("%s", utils.T(ctx, "error.file.access_denied_for_batch_update"))
		}
	}

	// –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏—Ö —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è
	ctxWithClient := ent.NewContext(ctx, client)
	files, err := client.File.Query().
		Where(file.IDIn(fileIDs...)).
		WithUploader().
		Limit(maxBatchUpdateFiles).
		All(ctxWithClient)
	if err != nil {
		return nil, 0, fmt.Errorf("%s", utils.T(ctx, "error.file.get_files_failed"))
	}

	// –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—Å–µ —Ñ–∞–π–ª—ã –Ω–∞–π–¥–µ–Ω—ã
	if len(files) != len(fileIDs) {
		return nil, 0, fmt.Errorf("%s", utils.T(ctx, "error.file.some_files_not_found"))
	}

	// –í–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏—è –ø–æ–ª–µ–π
	updatedCount := len(files)
	updatedFilesWithDetails, err := client.File.Query().
		Where(file.IDIn(fileIDs...)).
		WithUploader().
		Limit(maxBatchUpdateFiles).
		All(ctxWithClient)
	if err != nil {
		return nil, 0, fmt.Errorf("%s", utils.T(ctx, "error.file.get_updated_files_failed"))
	}

	return updatedFilesWithDetails, updatedCount, nil
}
